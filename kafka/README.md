# Kafka Streams для обробки даних про кавові напої

## Огляд системи

Система реалізує потокову обробку даних про кавові напої мережі Starbucks з використанням Apache Kafka та Kafka Streams. Архітектура системи базується на мікросервісному підході, де кожен компонент відповідає за окрему функцію в загальному процесі обробки даних. Дані зберігаються в PostgreSQL та передаються через Kafka для подальшої обробки та аналізу.

## Архітектура системи

Система складається з наступних компонентів:

PostgreSQL зберігає початкові дані про кавові напої, включаючи назву, калорійність, тип молока та інші характеристики. База даних взаємодіє з Kafka Producer, який зчитує дані та передає їх у Kafka кластер.

Apache Kafka забезпечує надійну передачу повідомлень між компонентами системи. Kafka Cluster включає в себе ZooKeeper для координації та управління, а також Kafka брокер для обробки повідомлень.

Kafka Streams Application виконує потокову обробку даних з використанням віконних операцій. Програма реалізує наступні функції обробки: фільтрація напоїв з високою калорійністю, групування за типом молока, агрегація калорій для напоїв без молока, віконні операції для підрахунку кількості напоїв та сумарної калорійності.

## Компоненти та їх функціональність

KafkaProducerFromDB зчитує дані з PostgreSQL та публікує їх у топік coffee_products. Компонент використовує пакетну обробку для ефективного завантаження даних та забезпечує надійну доставку повідомлень з підтвердженням.

KafkaStreamsApp реалізує логіку потокової обробки даних. Програма використовує різні типи вікон для агрегації даних: tumbling window тривалістю 5 хвилин для підрахунку калорій та hopping window з кроком 1 хвилина для підрахунку кількості напоїв. Додатково реалізована фільтрація напоїв за калорійністю та типом молока.

KafkaStreamResultsConsumer отримує результати обробки з різних топіків та відображає їх у консолі. Споживач обробляє як звичайні повідомлення, так і результати віконних операцій, форматуючи вивід для зручного читання.

ProducerMetricsCollector забезпечує збір та публікацію метрик роботи виробника. Система відстежує кількість повідомлень, обсяг переданих даних та пропускну здатність. Метрики публікуються у спеціальний топік producer_metrics кожні 10 повідомлень, що дозволяє моніторити продуктивність системи в реальному часі.

KafkaStreamsJoinApp реалізує операції об'єднання потоків даних про харчову цінність напоїв. Програма розділяє потік на високо- та низькокалорійні напої, після чого виконує їх об'єднання у вікні тривалістю 5 хвилин. Результати об'єднання публікуються в топік joined-nutrition-info, що дозволяє аналізувати співвідношення різних типів напоїв.

JoinedStreamConsumer обробляє результати об'єднання потоків та відображає їх у зручному для аналізу форматі. Компонент забезпечує моніторинг результатів об'єднання потоків в реальному часі.

DatabaseCleaner реалізує функціонал очищення застарілих даних з бази PostgreSQL. Компонент допомагає підтримувати оптимальну продуктивність бази даних та запобігає надмірному накопиченню історичних даних.

## Запуск системи

Для запуску системи необхідно виконати наступні кроки:

1. Запустити Docker контейнери командою docker-compose up -d. Це підніме PostgreSQL, Kafka, ZooKeeper та Kafka UI.

2. Дочекатися повного запуску PostgreSQL та виконати завантаження даних через CsvToPostgresLoader:
   java -cp target/kafka-1.0-SNAPSHOT-jar-with-dependencies.jar lab1.CsvToPostgresLoader

3. Запустити Kafka Producer для читання даних з PostgreSQL:
   java -cp target/kafka-1.0-SNAPSHOT-jar-with-dependencies.jar lab1.KafkaProducerFromDB

4. Запустити Kafka Streams застосунки для обробки даних:
   java -cp target/kafka-1.0-SNAPSHOT-jar-with-dependencies.jar lab1.KafkaStreamsApp
   java -cp target/kafka-1.0-SNAPSHOT-jar-with-dependencies.jar lab1.KafkaStreamsJoinApp

5. Запустити споживачів для перегляду результатів:
   java -cp target/kafka-1.0-SNAPSHOT-jar-with-dependencies.jar lab1.KafkaStreamResultsConsumer
   java -cp target/kafka-1.0-SNAPSHOT-jar-with-dependencies.jar lab1.JoinedStreamConsumer

Метрики виробника автоматично збираються та публікуються під час роботи KafkaProducerFromDB. Моніторинг метрик доступний через Kafka UI або через підписку на топік producer_metrics.

## Моніторинг та управління

Система включає Kafka UI, доступний за адресою http://localhost:8080. Інтерфейс дозволяє переглядати топіки, повідомлення, метрики споживання та виробництва.

Стан обробки та помилки логуються в консоль кожного компонента. Kafka Streams використовує локальне сховище стану для збереження проміжних результатів агрегації, що забезпечує відмовостійкість при збоях.

## Технічні характеристики

Система використовує наступні технології та їх версії:
- Apache Kafka 3.x
- Kafka Streams API
- PostgreSQL 13+
- Java 11+
- Docker та Docker Compose

Конфігурація системи оптимізована для обробки даних з урахуванням обмежень пам'яті та продуктивності. Встановлені таймаути та політики повторних спроб забезпечують надійну роботу при тимчасових збоях мережі або компонентів.

## Обробка помилок та відновлення

Система реалізує комплексний підхід до обробки помилок на всіх рівнях. Виробник та споживач використовують механізми підтвердження доставки повідомлень. Kafka Streams застосовує стратегію відновлення потоків при збоях та зберігає стан обробки для можливості продовження роботи з місця зупинки.

При виникненні помилок система логує детальну інформацію та застосовує відповідні стратегії відновлення. Це включає повторні спроби підключення до бази даних, перезапуск потоків обробки та очищення застарілих даних зі сховища стану.

